---
title: 'R exercise 4: Association Rule Mining'
author: "Kelsey Gonzalez and Laura Werthmann"
date: "October 3, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE,fig.width=5)
```

First we'll download the necessary packages, libraries and data.
```{r}
library (arules)
library(dplyr)
library(arulesViz)

options(scipen = 999)
```

# Associative Rule Mining of Boston Dataset
```{r}
data(Boston, package = "MASS")
```

### Reviewing the data

We can look at the different types of variable class within the Boston data
```{r}
lapply(Boston, class)
```

Most variables are shown as numeric, except for chas and rad, we'll review those and convert them to factors.
```{r}
unique(Boston$chas)
```
```{r}
unique(Boston$rad)
```

###Processing

We'll create a new dataset with the new variable class.
```{r}
b <- Boston
```

```{r}
b$chas <- factor(Boston$chas, labels = c("river", "noriver"))
b$rad <- factor(Boston$rad)
```

The variavle b$black will be cut for better interpretation.
```{r}
b$black <- cut(Boston$black, breaks = 4, labels = c(">31.5%", "18.5-31.5%", "8-18.5%", "<8%"))
```

Now we can discretize all the remaining variables in dataset b by putting them into 4 equal-width bins.

**We then pull out chas, rad, and black to mutate the other numeric variables, or put them into the 4 equal-width bins. after the bins are created we'll put our chas, rad and black variables back into the dataset. 

**Last, we'll turn the dataset b into a transactional dataset.
```{r}
discrt <-function(x) cut(x, breaks = 4, labels = c("low", "medlow", "medhigh", "High"))

b <- select(b, -c("chas", "rad", "black")) %>%
  mutate_all(funs(discrt)) %>%
  bind_cols(select(b, c("chas", "rad", "black")))

dim(b)

summary(b)


b <- as(b, "transactions")

```

Check the columns to make sure they're all in the bins:
```{r}
colnames(b)
```

Get a summary of the newly discretized and cute dataset.
```{r}
summary(b)
```

Now we'll inspect the first 9 transactions.
```{r}
inspect(b[1:3])
```

We can plot the frequency of the cut variables as seen below:
```{r}
itemFrequencyPlot(b, support=.3, cex.names=.8)
```

### Using association rules

Now we're going to apply the aprior method to the b dataset with a .025% support and 75% confidence, which gives us a minimum support count of 12 and 10 subsets before reaching a maximum.
```{r}
ars <- apriori(b, parameter = list(support=.025, confidence=.75))
```

We can get a summary of the data that includes the number of (x) left-hand-side and (y)right-hand-side rules that satisfy our support and confidence constraints.
```{r}
summary(ars)
```
As the example notes, we are interested in the association between pollution (NOX) and property value (MEDV) so we'll find the top 5 rules by confidence with "medv=High", and "medv=Low" attributes on the rhs:
```{r}
inspect(head(subset(ars, subset=rhs %in% "medv=High"), 5, by="confidence"))
```

Here we find the subsets of medv=low, lhs => rhs:
```{r}
inspect(head(subset(ars, subset=rhs %in% "medv=low"), 5, by="confidence"))
```

And now we'll compare the rhs in the lhs for high pollution (nox=High)
```{r}
 inspect(head(subset(ars, subset=rhs %in% "nox=High" | lhs %in% "nox=High")))
```

Instead of looking at high property value medV=High confidence, we'll look at support
```{r}
inspect(head(subset(ars, subset=rhs %in% "medv=High"), 5, by="support"))
```

Now we'll look at rules generated from maximal and closed itemsets:

We'll start with maximal itemsets that are at our support constraint and somewhat above the confidence constraint. The Maximal count is 13.
```{r}
inspect(head(subset(ars, subset=is.maximal(ars), 5, by="confidence")))
```

To find our closed datasets we need to find find and pull out the most frequent itemsets:\, 52 items are recorded:
```{r}
freq.itemsets <- apriori(b, parameter = list(target="frequent itemsets", support=.025))

```

Now we can find and review the closed itemsets, and of the 10 subsets, the first has a total of 13 closed itemetems.
```{r}
inspect(head(subset(ars, subset=is.closed(freq.itemsets), 5, by="confidence")))
closed = freq.itemsets[is.closed(freq.itemsets)]
summary(closed)

```

We can compare the frequencies to the maximum subsets which start at 4 with a maximum count of 4 transactions.
```{r}
maximal = freq.itemsets[is.maximal(freq.itemsets)]
summary(maximal)
```

Now we can look at shorter rules:
```{r}
inspect(head(subset(ars, subset= size(lhs) <5 & size(lhs) >1), 5, by="support"))
```

And modify the previous review by raising the lift.
```{r}
inspect(head(subset(ars, subset=size(lhs)<5 & size(lhs) >1 & lift >2), 5, by="support"))
```


### Data Visualization

first we'll review the interactive scatter plot for all 408638 rules. 
```{r}
plot(ars, engine = "htmlwidget", jitter = 0)
```

Now we'll look at a grouped matrix using new constraints. We use this to compare the support and lift association of lhs and rhs.

```{r}
somerules <- subset(ars, subset=size(lhs)>1 & confidence >.9 & support >0.5)
plot(somerules, method = "grouped")
```

This matrix with the top 21 rules shows the many antecedents that are found within the 4 consequents, {chas=river}" "{crim=low}"   "{black=<8%}"  "{zn=low}:
```{r}
plot(somerules, method = "matrix")
```

Use the 4 consequents to create a network graph. 
```{r}
plot(somerules, method = "graph", engine = "htmlwidget")
```



# [REQUIRED]
### Mine association rules from your dataset. 

# Associative Rule Mining of our Dataset, 
After going through this exercise, perform association rule learning on your dataset. Turn in both the R code for the exercise, and the R code for the practice using your datasets. You want to explore different thresholds, use the interactive vis tools provided by arulesViz, and find and report at least two interesting association rules from your dataset. 
```{r}
rm(list=ls())
load("LifeExpectancyData_3.Rdata")
data$Status = as.factor(data$Status)
data$Year = as.factor(data$Year)
data$Country = as.factor(data$Country)


data$Life <- cut(data$`Life expectancy`, 
                              breaks = 3, 
                              labels=c('low LE', 'middle LE', 'high LE'))
data$infantmort <- cut(data$`infant deaths`, 
                              breaks = 3, 
                              labels=c('low_infant', 'middle_infant', 'high_infant'))
data$expenditure <- cut(data$`Total expenditure`, 
                              breaks = 3, 
                              labels=c('low_expenditure','med_expenditure', 'high_expenditure'))
data$pop <- cut(data$Population, 
                              breaks = 3, 
                              labels=c('low_pop','med_pop', 'high_pop'))
data$bmi <- cut(data$BMI, 
                              breaks = 3, 
                              labels=c('low_BMI','med_BMI', 'high_BMI'))  
data$gdp <- cut(data$GDP, 
                              breaks = 3, 
                              labels=c('low_GDP','med_GDP', 'high_GDP'))  
data$alcohol <- cut(data$Alcohol, 
                              breaks = 3, 
                              labels=c('low_alc','med_alc', 'high_alc'))  

drops <- c("Alcohol",
           "percentage expenditure",
           "BMI",
           "GDP",
           "Diphtheria",
           "Life expectancy",
           "Measles",
           "infant deaths",
           "Total expenditure", 
           "thinness  1-19 years",  
           "thinness 5-9 years", 
           "Population", 
           "HIV/AIDS", 
           "Polio",
           "under-five deaths",
           "Adult Mortality",
           "Income composition of resources",
           "Schooling")
data <- data[ , !(names(data) %in% drops)]
```

transform the dataframe b to a transactions dataset, where each row is described by a set of **binary** variables (this is “bitmap indexing” we learned in Chapter 4 in the textbook) 
transactions data are often very large and sparse, directly looking at it won’t give your much information.You can see how the columns are constructed by using colnames(), or see a summary() of it. To see the records, use inspect(): inspect(b[1:9]) show the first 9 transactions.
```{r}
b <- as(as.data.frame(data), "transactions") 

inspect(b[1:3]) 
```

```{r}
ars <- apriori(b, parameter = list(support=0.30, confidence=0.75))
#222 rules created
```
```{r}
#find rules generated from maximal/closed itemsets: 
#maximal itemsets
inspect(head(subset(ars, subset=is.maximal(ars), 5, by="support")))
```

```{r}
inspect(head(subset(ars, subset=rhs %in% "Life=low LE"), 5, by="support"))
inspect(head(subset(ars, subset=rhs %in% "Life=middle LE"), 5, by="support"))
inspect(head(subset(ars, subset=rhs %in% "Life=high LE"), 5, by="support"))

```


```{r}
# need to find freq itemsets to find closed itemsets:
freq.itemsets <- apriori(b, parameter=list(target="frequent itemsets", support=0.25))
closed = freq.itemsets[is.closed(freq.itemsets)]
inspect(head(subset(freq.itemsets, subset=is.closed(freq.itemsets), 5, by="support")))
```


```{r}
#find maximal itemsets
maximal = freq.itemsets[is.maximal(freq.itemsets)]
summary(maximal)
```

```{r}
#check shorter rules
inspect(head(subset(ars, subset= size(lhs)<5 & size(lhs) >1), 5, by="support"))

#note the above rules have high support and confidence but low lift.
inspect(head(subset(ars, subset= size(lhs)<5 & size(lhs) >1 & lift > 1), 5, by="support"))
```

Plotting rules by confidence and support
```{r}
plot(ars, engine = "htmlwidget", jitter = 0)
``` 


```{r}
#grouped 
somerules <- subset(ars, subset=size(lhs) & confidence>0.90 & support>0.3)
plot(somerules, method="grouped")
```

```{r}
plot(somerules, method="graph", engine="htmlwidget")
```


### Discuss a couple of interesting rules mined. 

The Association rules produced from our data set have quite low lift, meaning the rules aren't relatively important. Whereas in the Boston dataset with lifts of over 2, our own dataset only show a maximum lift of around 1.2. In addition, our main variable of interest, life expectancy, has very few rules with higher support. 

Rule 1
{Status=Developing, infantmort=low_infant, expenditure=low_expenditure} => {alcohol=low_alc}  
support: 0.385  
confidence: 0.811  
lift: 1.35  

Rule 2
{Status=Developing, Life=middle LE, infantmort=low_infanct, gdp=low_GDP} => {pop=low_pop}  
support: 0.307  
confidence: 0.991  
lift: 1.28  

Rule 3
{Status=Developing, infantmort=low_infanct, bmi=low_BMI} => {pop=low_pop}  
support: 0.302  
confidence: 0.818  
lift: 1.05  